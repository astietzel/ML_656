{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "name": "Module1_WageRegressions.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/danielbauer1979/ML_656/blob/main/Module1_WageRegressions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Multivariate Ordinary Least-Squares (OLS) Regression\n",
        "\n",
        "In this module, we introduced univariate regression. In this module, we extended regression modeling to include $p$ predictors.  Hence, the data set will include $n$ observations $(y_i,x_{i,1},...,x_{i,p})$, $1 \\leq i \\leq n$, and we assume:\n",
        "$$\n",
        "y_i = f(x_i) + \\varepsilon_i = \\beta_0+\\sum_{j=1}^p \\beta_j\\,x_{i,j} + \\varepsilon_i.\n",
        "$$\n",
        "Like in the univariate case, OLS regression determines the estimate $\\hat{\\beta}$ that best approximates the training data in the *least-squares sense*:\n",
        "$$\n",
        "\\hat{\\beta}^{\\text{OLS}} = \\text{argmin}_{\\beta}\\left\\{\\sum_{i=1}^n \\left(y_i - \\left(\\beta_0 + \\sum_{j=1}^p \\beta_j\\,x_{i,j}\\right)\\right)^2 \\right\\}.\n",
        "$$\n",
        "The OLS estimate also still has nice properties as we had discussed in this module.\n",
        "\n",
        "Let's evaluate multivariate regression in an example setting.\n",
        "\n",
        "## Wage Regression\n",
        "\n",
        "We have a rather old dataset, namely cross-sectional sample from the  May 1985 Current Population Survey by the US Census Bureau. These data include (hourly) wages for 534 individuals, where we have information on age, sex (0 for male, 1 for female), race (H for Hispanic, W for White, O for Other), years of education, et cetera. Let's take a look:\n",
        "\n",
        "\n",
        "We start by loading libraries. Here, importantly we will rely on [scikit-learn](https://scikit-learn.org/stable/) for running the regression. While there are many more comfortable packages for the specific task of running a linear regression (formula-based more similar to the look and feel in `R`), scikit-learn is one of the most popular predictive modeling toolboxes and we will use it for many (!) models/algorithms throughout this course:"
      ],
      "metadata": {
        "id": "WP5xYitAeAYC"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XahgdBpGdXkF"
      },
      "source": [
        "import numpy as np \n",
        "import pandas as pd\n",
        "from sklearn.linear_model import LinearRegression\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.stats as st"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6PpZsYF-ScgG"
      },
      "source": [
        "To make the data available, you can clone my github repository into your colab notebook, via (remove the hashtag of course):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZO_5zXXETBfG"
      },
      "source": [
        "!git clone https://github.com/danielbauer1979/ML_656.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j7cLV6zJT2se"
      },
      "source": [
        "If you now list the content..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6rg6bLqyT_HJ"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3PofGtKyUBes"
      },
      "source": [
        "you should see `ML_656` listed. And we can pull the data from there:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gwN41ynLdXkG"
      },
      "source": [
        "wage_data = pd.read_csv('ML_656/Wages_1985_Current_Population_Survey.csv')\n",
        "wage_data.head() #the syntax makes clear that data is an object!"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nbj6VFNvTYe8"
      },
      "source": [
        "So we have the data available. Let's look at aggregate stats."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wD2WIFIEdXkH"
      },
      "source": [
        "wage_data.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KbZdCBioUNaz"
      },
      "source": [
        "OK, so let's run the wage regression using sklearn. For that we first have to recode our categorical variables."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fnKpUSoMjjdO"
      },
      "source": [
        "wage_data['Race'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-LKuEUzVkC11"
      },
      "source": [
        "wage_data['Race_H'] = np.where(wage_data['Race'] == \"H\", 1, 0)\n",
        "wage_data['Race_O'] = np.where(wage_data['Race'] == \"O\", 1, 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "021F5z3mVFk8"
      },
      "source": [
        "A more streamlines way of doing this is via `get_dummies` in pandas:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i8q556FpVXAu"
      },
      "source": [
        "pd.get_dummies(wage_data['Race']).head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c1dcpByoV_qK"
      },
      "source": [
        "We could then add in via `wage_data['Race_H'] = pd.get_dummies(wage_data['Race'])['H']` etc. Or we can just get all our dummies via `X = pd.get_dummies(wage_data['Race'], drop_first=True).head()`\n",
        "\n",
        "So let's define our features:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zl5JCUhmgV8N"
      },
      "source": [
        "X1 = wage_data[['Sex','Age','Race_H','Race_O']]\n",
        "y = wage_data['Wage']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's run our first linear regression model:"
      ],
      "metadata": {
        "id": "51F5zMK6fkhG"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0xASAMZGhYCD"
      },
      "source": [
        "model1 = LinearRegression(fit_intercept=True)\n",
        "model1.fit(X1, y)\n",
        "print(model1.intercept_)\n",
        "print(model1.coef_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-coohpg2X2f3"
      },
      "source": [
        "So the presentation of the regression results is not as neat as when using R or statsmodels. But as we will see `sklearn` will make it easy to build more advanced models. Again, that's its purpose. \n",
        "\n",
        "Let's run a second regression with additional features:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gL6rdGrGlafl"
      },
      "source": [
        "X2 = wage_data[['Sex','Age','Race_H','Race_O','Yrs_Ed','Sthrn_Rgn']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RlprC2nEdXkI"
      },
      "source": [
        "model2 = LinearRegression(fit_intercept=True)\n",
        "model2.fit(X2, y)\n",
        "print(model2.intercept_)\n",
        "print(model2.coef_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M1Z6fosaZTDs"
      },
      "source": [
        "Let's run the full regression:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AVWT7UjPdXkJ"
      },
      "source": [
        "Occup_d = pd.get_dummies(wage_data['Occup'], prefix='Occup', drop_first=True)\n",
        "Race_d = pd.get_dummies(wage_data['Race'], prefix='Race', drop_first=True)\n",
        "Sect_d = pd.get_dummies(wage_data['Sect'], prefix='Sect', drop_first=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A50Q9aYidXkJ"
      },
      "source": [
        "X = wage_data.drop(columns=['Wage','Occup','Race','Sect'])\n",
        "X = pd.concat([X,Occup_d,Race_d,Sect_d], axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oCVcaApOZrB3"
      },
      "source": [
        "model3 = LinearRegression(fit_intercept=True)\n",
        "model3.fit(X, y)\n",
        "print(model3.intercept_)\n",
        "print(model3.coef_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BoXT14zmbT36"
      },
      "source": [
        "And let's check the residuals."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fiqzgjEAdXkK"
      },
      "source": [
        "ypred = model3.predict(X)\n",
        "eps = y - ypred\n",
        "plt.hist(eps)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}