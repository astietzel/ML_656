{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/danielbauer1979/ML_656/blob/main/Module4_LASSOandCaravan.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#Regularized Regression\n",
        "\n",
        "In this tutorial, we will discuss regularized regression approaches, particularly least absolute shrinkage and selection operator -- or, in short, the [LASSO](http://statweb.stanford.edu/~tibs/lasso.html/) -- in the context of predicting claim sizes.\n",
        "\n",
        "Let's install relevant packages. Again, we're going to rely on the statistical learning toolkit ski-cit learn, which provides LASSO regression but also has many other predictive models. As before, it is less comfortable to use than some of the other packages and, unlike R, does not support formulas. But it is versatile and fast, and therefore one of the most popular predictive modeling toolkits."
      ],
      "metadata": {
        "id": "dHbED4M_i3Vp"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eDKmQZZSUufH"
      },
      "source": [
        "import numpy as np \n",
        "import matplotlib.pyplot as plt  \n",
        "import pandas as pd \n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
        "from sklearn.metrics import confusion_matrix, roc_curve, auc\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.preprocessing import scale\n",
        "from sklearn.neighbors import KNeighborsClassifier"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ridge and LASSO Regression\n",
        "\n",
        "Ridge and LASSO regression are both examples of *regularized* regression approaches.  In what follows, we will first briefly review the corresponding approaches, and particularly highlight how they differ from their unregularized counterparts.   We then will work through a simulated example to become familiar with the impact of the *tuning parameter* on the resulting coefficient estimates.  We will also determine the in- and out-of-sample fit depending on the choice of the tuning parameter, uncovering a familiar relationship.\n",
        "\n",
        "## Review of Concepts and Maths\n",
        "\n",
        "In a conventional (linear) regression problem with independent variables $x_i$ and depedent variables $y_i$, we are determining the best fit in the least-squares sense:\n",
        "$$\n",
        "\\hat{\\beta}^{\\text{OLS}} = \\text{argmin}_{\\beta}\\left\\{\\sum_{i=1}^n \\left(y_i - \\left(\\beta_0 + \\sum_{j=1}^p \\beta_j\\,x_{i,j}\\right)\\right)^2 \\right\\}.\n",
        "$$\n",
        "Within a *regularized* approach, we now include penalties for choosing many or large parameters:\n",
        "$$\n",
        "\\hat{\\beta}^{\\text{REG}}_\\lambda = \\text{argmin}_{\\beta}\\left\\{\\sum_{i=1}^n \\left(y_i - \\left(\\beta_0 + \\sum_{j=1}^p \\beta_j\\,x_{i,j}\\right)\\right)^2 + \\lambda \\times R(\\beta) \\right\\}.\n",
        "$$\n",
        "Here, $R(\\beta)$ is a so-called *regularization* term that imposes a penalty on the complexity of the regression equation.  In particular, within Rigde regression the penalty term is *quadratic*, $R(\\beta) = \\sum_{j=1}^p \\beta_j^2,$ wheras the LASSO uses an L1 penalty, $R(\\beta) = \\sum_{j=1}^p |\\beta_j|.$  \n",
        "\n",
        "We call $\\lambda$ the *tuning parameter*, and it governs how sizable the complexity penalty will be.  In particular, note that for $\\lambda=0$ we are back to the unregularized problem, whereas for large lambda the penalty will be severe -- so this will lead to *shrinkage* of the coefficient estimates.  As $\\lambda$ becomes large and larger, the prediction will more and more closely resemble a *constant* prediction, $\\hat{y}_i = \\beta_0.$  Thus, the choice of the tuning parameter will directly be related to trading off a reduction in variance (due to shrinkage) with an increase in bias (due to the less flexible model fit).  Again, we will explore these aspects in more detail in the context of our example below.\n"
      ],
      "metadata": {
        "id": "f-l0xHP4RpIe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Caravan Insurance Application\n",
        "\n",
        "We look at the `Caravan` insurance data set included in the ISLR textbook. As indicated in Section 4.6.6, it is a dataset that includes 85 predictors that measure demographic characteristics for 5,822 individuals and \"Purchase,\" which indicates whether or not a given individual purchases a caravan insurance policy. \n",
        "\n",
        "As usual, let's load some relevant libraries:\n",
        "\n",
        "Let's load our dataset:"
      ],
      "metadata": {
        "id": "zW1Vsrn9jxxz"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ha1vAQH4VErB"
      },
      "source": [
        "!git clone https://github.com/danielbauer1979/ML_656.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OtWs9QsTUufJ"
      },
      "source": [
        "Caravan = pd.read_csv('ML_656/Caravan.csv', index_col=0) "
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Some Data Exploration"
      ],
      "metadata": {
        "id": "22qXzCaej4ra"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yun-91lhUufL"
      },
      "source": [
        "Caravan.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Variables 1-43 represent sociodemographic data, variables 44-86 describe product ownership, and Variable 86 (Purchase) indicates whether the customer purchased a caravan insurance policy.\n",
        "\n",
        "Let's consider some aggregate statistics:"
      ],
      "metadata": {
        "id": "0bJ5JIlqkCC4"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BySMAV24UufL"
      },
      "source": [
        "Caravan.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "And check how many people purchase insurance:"
      ],
      "metadata": {
        "id": "-6_uDvoYkdtV"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "li6ha6XDUufM"
      },
      "source": [
        "Caravan['Purchase'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "So only roughly 6% of all people buy caravan insurance.  That will be costly for an insurance agent because for every client she or he visits, only 6 in 100 will purchase insurance.  So let's use our knowledge about classification to help out the sales force, and let's try to determine individuals (based on their characteristics) that are more likely to purchase a policy.\n",
        "\n",
        "## Predictive Modeling\n",
        "\n",
        "Let's split into a training and test set to get going"
      ],
      "metadata": {
        "id": "ndkNHfnAkhqQ"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t_eYPqIeUufO"
      },
      "source": [
        "Train, Test = train_test_split(Caravan, test_size=0.25, random_state=1)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JRc-UTJwUufR"
      },
      "source": [
        "X_train = Train.drop(['Purchase'], axis=1)\n",
        "y_train = Train['Purchase']\n",
        "X_test = Test.drop(['Purchase'], axis=1)\n",
        "y_test = Test['Purchase']"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's start with a vanilla logistic regression model:"
      ],
      "metadata": {
        "id": "E1WDfjihk5vJ"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bLxhzONLUufS"
      },
      "source": [
        "logistic_model = LogisticRegression(fit_intercept=True, max_iter=1000)\n",
        "logistic_model.fit(X_train,y_train)\n",
        "y_pred_logistic = logistic_model.predict(X_test)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's look at the confusion matrix resulting from our predictions (here the predicted probabilities are already coerced to classes):"
      ],
      "metadata": {
        "id": "Sga9f0aslKB9"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1fiMB1kDXqNS"
      },
      "source": [
        "confusion_matrix(y_test, y_pred_logistic)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We don't get a single positive one right -- so not great performance.  Of course, we could choose a different cutoff.  Let's evaluate the AUC, where we first have to convert the predictions to probabilities:"
      ],
      "metadata": {
        "id": "SwgMerVCbPUn"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pox4agQZUufT"
      },
      "source": [
        "y_pred_logistic = logistic_model.predict_proba(X_test)\n",
        "def Extract(lst): \n",
        "    return [item[0] for item in lst] \n",
        "y_pred_logistic = Extract(y_pred_logistic)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MqrGZiD4UufU"
      },
      "source": [
        "fpr, tpr, threshold = roc_curve((Test['Purchase'] == 'No'), y_pred_logistic) \n",
        "roc_auc = auc(fpr, tpr)\n",
        "plt.title('Receiver Operating Characteristic') \n",
        "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc) \n",
        "plt.legend(loc = 'lower right')\n",
        "plt.plot([0, 1], [0, 1],'r--') \n",
        "plt.xlim([0, 1])\n",
        "plt.ylim([0, 1]) \n",
        "plt.ylabel('True Positive Rate') \n",
        "plt.xlabel('False Positive Rate') \n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's check LDA:"
      ],
      "metadata": {
        "id": "3GjtimWCUdzM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "LDA_model = LinearDiscriminantAnalysis()\n",
        "LDA_model.fit(X_train,y_train)\n",
        "y_pred_LDA = LDA_model.predict(X_test)\n",
        "np.sum(y_pred_LDA == 'Yes')"
      ],
      "metadata": {
        "id": "j3qDvRwOUiCb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "So it looks like we get a few positives. Let's check confusion matrix and AUC:"
      ],
      "metadata": {
        "id": "tZ60CbHvUwti"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "confusion_matrix(y_test, y_pred_LDA)"
      ],
      "metadata": {
        "id": "0bdtydH8Ur5R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_LDA = LDA_model.predict_proba(X_test) \n",
        "y_pred_LDA = Extract(y_pred_LDA)"
      ],
      "metadata": {
        "id": "lpmv-7M8Uvp2"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fpr, tpr, threshold = roc_curve((Test['Purchase'] == 'No'), y_pred_LDA) \n",
        "roc_auc = auc(fpr, tpr)\n",
        "plt.title('Receiver Operating Characteristic') \n",
        "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc) \n",
        "plt.legend(loc = 'lower right')\n",
        "plt.plot([0, 1], [0, 1],'r--') \n",
        "plt.xlim([0, 1])\n",
        "plt.ylim([0, 1]) \n",
        "plt.ylabel('True Positive Rate') \n",
        "plt.xlabel('False Positive Rate') \n",
        "plt.show()"
      ],
      "metadata": {
        "id": "JxnUwR_3U6S5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "So a bit of an improvement."
      ],
      "metadata": {
        "id": "Zd557TuhU8ES"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's compare these results to an L1-regularized logistic regression -- a.k.a. LASSO logistic regression -- to see if that yields an improvement.  After all, there are many features so possibily selection is important:"
      ],
      "metadata": {
        "id": "yPQS5Ph-bgHQ"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NpGV3GTNUufS"
      },
      "source": [
        "lassolog_model = LogisticRegression(\n",
        "    penalty='l1',\n",
        "    solver='saga',\n",
        "    max_iter=2000)  # or 'liblinear'\n",
        "lassolog_model.fit(X_train, y_train)\n",
        "y_pred_lassolog = lassolog_model.predict(X_test)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's evaluate the predictions:"
      ],
      "metadata": {
        "id": "4VybTP5kbov2"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-2-kcNAWaYIP"
      },
      "source": [
        "confusion_matrix(y_test, y_pred_lassolog)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's try to tune the model a bit better (this part takes a bit, so you can skip):"
      ],
      "metadata": {
        "id": "w_z3g8vObrP4"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "umvGcMO-UufU"
      },
      "source": [
        "C = [50, 10, 1, .1, 0.05,.01,.001]\n",
        "for c in C:\n",
        "  lassologcv_model = LogisticRegression(penalty='l1',C=c,class_weight = 'balanced',solver='liblinear',max_iter=2000)\n",
        "  scores = cross_val_score(lassologcv_model, X_train, y_train, cv=5, scoring=\"f1_micro\")  \n",
        "  print(scores)\n",
        "  print(np.mean(scores))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's evaluate predictions:"
      ],
      "metadata": {
        "id": "yRb6mumTcSiT"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f4uZ-k0_bF7d"
      },
      "source": [
        "lassologcv_model = LogisticRegression(penalty='l1',C=50,class_weight = 'balanced',solver='liblinear',max_iter=2000)\n",
        "lassologcv_model.fit(X_train, y_train)\n",
        "y_pred_lassologcv = lassologcv_model.predict(X_test)\n",
        "confusion_matrix(y_test, y_pred_lassologcv)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "So at least we find some positives. And let's check the AUC again:"
      ],
      "metadata": {
        "id": "t8K_OmYIcX_0"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kGUfjYVWUufV"
      },
      "source": [
        "y_pred_lassologcv = lassologcv_model.predict_proba(X_test)\n",
        "y_pred_lassologcv = Extract(y_pred_lassologcv)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D8JbflZvUufW"
      },
      "source": [
        "fpr, tpr, threshold = roc_curve((Test['Purchase'] == 'No'), y_pred_lassologcv) \n",
        "roc_auc = auc(fpr, tpr)\n",
        "plt.title('Receiver Operating Characteristic') \n",
        "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc) \n",
        "plt.legend(loc = 'lower right')\n",
        "plt.plot([0, 1], [0, 1],'r--') \n",
        "plt.xlim([0, 1])\n",
        "plt.ylim([0, 1]) \n",
        "plt.ylabel('True Positive Rate') \n",
        "plt.xlabel('False Positive Rate') \n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "No substantial improvement. So it looks like here selecting variables doesn't make a huge difference. Possibly more advanced learners that can spot relevant interactions will perform better."
      ],
      "metadata": {
        "id": "d5FoaO1Echr1"
      }
    }
  ]
}